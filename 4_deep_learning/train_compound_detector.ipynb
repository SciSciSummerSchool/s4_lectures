{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an example for using CNN to perform chart classification \n",
    "(this code is modified from https://www.pyimagesearch.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: imutils in /opt/conda/lib/python3.8/site-packages (0.5.4)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=40,\n",
    "\tzoom_range=0.3,\n",
    "\twidth_shift_range=0.3,\n",
    "\theight_shift_range=0.3,\n",
    "\tshear_range=0.3,\n",
    "\thorizontal_flip=True,\n",
    "    #preprocessing_function=None\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25604 images belonging to 7 classes.\n",
      "Found 6400 images belonging to 7 classes.\n",
      "Found 8000 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=config.BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=config.BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=config.BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Area': 0,\n",
       " 'Bar': 1,\n",
       " 'Box': 2,\n",
       " 'Heatmap': 3,\n",
       " 'Line': 4,\n",
       " 'Scatter': 5,\n",
       " 'Violin': 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preparing model...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "print(\"[INFO] preparing model...\")\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(32,activation=\"relu\")(headModel)\n",
    "headModel = Dense(32,activation=\"relu\")(headModel)\n",
    "headModel = Dense(len(config.CLASSES), activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "opt = Adam(lr=config.INIT_LR, decay=config.INIT_LR / config.NUM_EPOCHS)\n",
    "# loss = \"categorical_crossentropy\" for more then two classes\n",
    "# loss = \"binary_crossentropy\" for two classes\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "800/800 [==============================] - 793s 970ms/step - loss: 0.7997 - accuracy: 0.7503 - val_loss: 0.1681 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // config.BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // config.BS,\n",
    "\tepochs=config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Area       1.00      0.99      1.00       965\n",
      "         Bar       0.96      1.00      0.98      2008\n",
      "         Box       0.99      0.94      0.96      1002\n",
      "     Heatmap       0.99      0.98      0.98      1007\n",
      "        Line       1.00      0.98      0.99      1020\n",
      "     Scatter       0.96      0.98      0.97       982\n",
      "      Violin       1.00      0.99      0.99      1016\n",
      "\n",
      "    accuracy                           0.98      8000\n",
      "   macro avg       0.99      0.98      0.98      8000\n",
      "weighted avg       0.98      0.98      0.98      8000\n",
      "\n",
      "[INFO] saving model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict(testGen,steps = totalTest//config.BS)\n",
    "\t#steps=(totalTest // config.BS) + 1)\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "#print(accuracy_score(testGen.classes, predIdxs))\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "model.save(config.MODEL_PATH, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an example to predict a real image with url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR-HV5bf6hRFSIVySrBZAKN1YtB3qDAIsaOig&usqp=CAU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=P size=286x176 at 0x7FE51C34AD30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.save(\"tmp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array = tf.keras.preprocessing.image.img_to_array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"tmp.png\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "#you may do preprocessing to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05046218, 0.31704998, 0.39239898, 0.09547256, 0.06244782,\n",
       "        0.07051211, 0.01165635]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_preprocessed = preprocess_input(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10645764, 0.1427337 , 0.41025072, 0.2566854 , 0.03809393,\n",
       "        0.04016966, 0.00560887]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
