{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Science of Science Summer School (S4) 2022\n",
    "## Day 4: Deep Learning\n",
    "### Neural networks, optimization\n",
    "- Daniel E. Acuna, Department of Computer Science, University of Colorado, Boulder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Object recognition problem\n",
    "- A bit of neuroscience.\n",
    "- From logistic regression to neural networks.\n",
    "- The perceptron.\n",
    "- Multi-layer perceptron.\n",
    "- Training neural networks.\n",
    "- Demo with multi-layer perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The object recognition problem\n",
    "- Detect an object present in an image.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl1.png\" width=\"100%\" align=\"center\"></center>  \n",
    "\n",
    "<br>\n",
    "<center>Caltech101 dataset (year 2003)</center>\n",
    "<center>101 categories of objects, each category has 40 to 800 images</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A high dimensional problem\n",
    "- Each image is 300 x 200 x 3 pixels (width x height x channels.)\n",
    "  - 180,000 \"raw\" features.  \n",
    "  \n",
    "- Relationship between raw features and classes is highly non-linear.\n",
    "  - Spatial features that could appear anywhere on the image.\n",
    "  - Local features (e.g., shapes) vs global features (e.g., contrast.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A high dimensional problem (2)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl2.png\" width=\"70%\" align=\"center\"></center>\n",
    "<br>\n",
    "<center><sup>Credit: https://www.st-andrews.ac.uk/~www_pa/Scots_Guide/info/signals/pixels/</sup></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A problem with logistic regression\n",
    "- We are trying to learn:  \n",
    "\n",
    "$$p(y \\mid X) = \\frac{1}{1 + \\exp(-(\\theta_0 + \\sum_{j>0}{x_j\\theta_j}))}$$  \n",
    "\n",
    "- So only a linear relationship between pixels $x$ and class $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classic data science\n",
    "- Features fed into the algorithms are meaningful and provided by experts.  \n",
    "\n",
    "- Machine learning algorithms only provide 1 or 2 step transformations.  \n",
    "\n",
    "- Complexity of problems is relatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A bit of neuroscience\n",
    "- Deep learning takes loose inspiration from how the brain works.  \n",
    "\n",
    "- At an architectural level, the brain works by combining specialized neurons in hierarchies.  \n",
    "\n",
    "- E.g., the visual system is organized into several areas (around 8.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/unit-10/unit-10-0_csordl3.png\" width=\"80%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/unit-10/unit-10-0_csordl4.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A bit of neuroscience (2)\n",
    "- The brain has relatively \"simple\" processing units: neurons. <br>   \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl5.png\" width=\"80%\" align=\"center\"></center>\n",
    "<br>\n",
    "<center><sup>Credit: http://www.intechopen.com/source/html/39067/media/image1.png</center></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/unit-10/unit-10-0_csordl6.png\" width=\"80%\" align=\"center\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/unit-10/unit-10-0_csordl7.png\" width=\"80%\" align=\"center\"></center>  \n",
    "$$p(y \\mid X) = \\frac{1}{1 + \\exp(-(\\theta_0 + \\sum_{j>0}{x_j\\theta_j}))}$$  \n",
    "**<center>A model for the probability of an action potential!</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Of course reality is a lot more complicated\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl8.png\" width=\"60%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Of course reality is a lot more complicated\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl8_1.gif\" width=\"60%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The general idea of artificial neural networks\n",
    "- Simple processing units with linear or non-linear functions $f$.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl9.png\" width=\"50%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The general idea of artificial neural networks (2)\n",
    "- Multiple units belong to layers and those layers are interconnected to other layers.    \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl10.png\" width=\"70%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A highly non-linear function\n",
    "- The output now depends on nested functions:  \n",
    "\n",
    "\n",
    "$$y = \\underbrace{f_3\\left(\\;\\underbrace{f_2\\left(\\;\\underbrace{f_1(x)}_{\\text{first layer}} + b_0\\right)}_{\\text{second layer}} + b_1\\right) + b_2}_{\\text{third layer (nested non-linearities)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advantages and disadvantages of ANN\n",
    "- Pros:\n",
    "  - Can fit complex non-linear relationships.\n",
    "  - Easy to try different types of layers.\n",
    "  - Inspired by a very effective machine (the brain!)  \n",
    "  \n",
    "- Cons:\n",
    "  - Many parameters.\n",
    "  - Easy to overfit.\n",
    "  - Needs lots of training data.\n",
    "  - Takes a long time to fit.\n",
    "  - The use of brain research is really minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to train a neural network?\n",
    "- We define a loss function and try to find best value:  \n",
    "\n",
    "$$\\arg\\min_{\\Theta} {l(\\;f_\\Theta(X),y)}$$\n",
    "\n",
    "- For example:  \n",
    "\n",
    "$$l(\\;f_\\Theta(X),y) = \\sum(\\;f_\\Theta(X_i) - y_i)^2$$  \n",
    "<br>\n",
    "<center>where $f_\\Theta(X)$ is the function represented by the entire network.</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimizing the loss function\n",
    "- There is no close solution to the loss function:  \n",
    "\n",
    "$$\\arg\\min_{\\Theta} {l(\\;f_\\Theta(X),y)}$$  \n",
    "\n",
    "- In all but the trivial cases, the loss function is *non-convex* (hard to optimize.)  \n",
    "\n",
    "- A very effective approach to perform stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent\n",
    "- Gradient descent is a simple approach to iteratively minimize a loss function.  \n",
    "\n",
    "- Intuitively, we want to follow the *negative* of the gradient to find the minimum of a loss function:  \n",
    "\n",
    "$$\\Theta_{t+1} = \\Theta_{t} - \\eta \\nabla l(\\;f_\\Theta(X),y)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: example\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl11.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: example (2)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl12.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: example (3)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl13.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: example (4)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl14.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: example (5)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl15.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: problems\n",
    "- It finds the global optimum when function is convex (e.g., a parabola) and the learning rate is appropriate.\n",
    "- But:\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl16.png\" width=\"50%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic gradient descent\n",
    "- If we look at a fraction of the training data, we only observe a (noisy) sample of the loss function.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl17.png\" width=\"80%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic gradient descent (2)\n",
    "- If we look at a fraction of the training data, we only observe a (noisy) sample of the loss function.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl18.png\" width=\"80%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic gradient descent (3)\n",
    "- If we look at a fraction of the training data, we only observe a (noisy) sample of the loss function.  \n",
    "\n",
    "- Stochastic gradient descent is good for big data (we only need pieces at a time.)  \n",
    "\n",
    "- Stochastic gradient descent can escape local minima.  \n",
    "\n",
    "- As long as we can compute gradients, we can use function we want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worked-out example\n",
    "- A simple neural network with one neuron and one layer.  \n",
    "\n",
    "- More assumptions sigmoid activation $f$ and $a = y$.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl19.png\" width=\"70%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worked-out example (2)\n",
    "- A simple neural network with one neuron and one layer.  \n",
    "\n",
    "- More assumptions sigmoid activation $f$ and $a = y$.  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl20.png\" width=\"70%\" align=\"center\"></center>  \n",
    "**<center>Similar to Logistic Regression!</center>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worked-out example (3)\n",
    "- Using quadratic loss function, let’s work out the stochastic gradient descent update rule:  \n",
    "\n",
    "$$\\Theta_{t+1} = \\Theta_{t} - \\eta \\nabla l(\\;f_\\Theta(X),y)$$    \n",
    "\n",
    "$$l(\\;f_\\Theta(X),y) = (\\;f(z) - y)^2 = \\left(\\sigma\\left(\\sum{x_j\\theta_j} - y\\right)\\right)^2$$  \n",
    "\n",
    "$$\\nabla{l(\\;f_\\Theta(X),y)} = \\left[\\frac{dl}{d\\theta_0}, \\frac{dl}{d\\theta_1}, \\ldots, \\frac{dl}{d\\theta_m}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worked-out example (4)\n",
    "- Let’s pick one the gradients:  \n",
    "\n",
    "\\begin{align}\n",
    "\\nabla{l(\\;f_\\Theta(X),y)} &= \\left[\\frac{dl}{d\\theta_0}, \\frac{dl}{d\\theta_1}, \\ldots, \\frac{dl}{d\\theta_m}\\right] \\\\\n",
    "\\frac{dl}{d\\theta_j} &= \\frac{d\\left(\\sigma\\left(\\sum{x_j\\theta_j} - y\\right)\\right)^2}{d\\theta_j}\n",
    "\\end{align}\n",
    "\n",
    "- We are trying to compute the gradient of a nested function, what to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worked-out example (5)\n",
    "<br>\n",
    "<left><img src=\"./images/unit-10/unit-10-0_csordl21.png\" width=\"20%\" align=\"left\"></left>\n",
    "\n",
    "- We can apply basic calculus.  \n",
    "\n",
    "- By representing each nested function on its own:  \n",
    "\n",
    "$$\\frac{d\\left(\\sigma\\left(\\sum{x_j\\theta_j} - y\\right)\\right)^2}{d\\theta_j} = \\frac{d}{d\\theta_j} l(a(z(\\theta_0, \\cdots, \\theta_m, x), y)$$\n",
    "\n",
    "- Where $a$ is the activation, and $z$ is the summation.  \n",
    "\n",
    "- Now we can simply apply the chain rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Worked-out example (6)\n",
    "- We can apply basic calculus.\n",
    "- By representing each nested function on its own:\n",
    "$$\\frac{d}{d\\theta_j} l(a(z(\\theta_0, \\cdots, \\theta_m, x), y) = \\frac{dl}{da}\\frac{da}{dz}\\frac{dz}{d\\theta_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\frac{dl}{da} = 2(a - y) \\qquad\n",
    "\\frac{da}{dz} = a(1-a) \\qquad\n",
    "\\frac{dz}{d\\theta_j} = x_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align}\n",
    "\\Theta_j^{\\text{new}} &\\leftarrow \\Theta_j^{\\text{old}} - \\eta \\;{2(a-y)} \\;{a(1-a)} \\;{x_j} \\\\\n",
    "&\\leftarrow \\Theta_j^{\\text{old}} - \\eta \\;{\\left(\\sigma\\left(\\sum{x_j\\theta_j}\\right) - y\\right)} \\;{\\sigma\\left(\\sum{x_j\\theta_j}\\right)} \\;{\\left(1 - \\sigma\\left(\\sum{x_j\\theta_j}\\right)\\right)} {x_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "- The previous example is the basis of stochastic gradient descent for several layers.\n",
    "- **Backpropagation** is a general algorithm that exploits the structure of the chain rule when applied to layers.\n",
    "- To understand backpropagation, we need to understand middle layers:  \n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl22.png\" width=\"60%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation (2)\n",
    "- $\\theta_{ij}^{L-2}$: connection between neuron $j$ in layer $L-2$ to neuron $i$ in layer $L-1$.\n",
    "\n",
    "- Representing all connections from $L-2$ to $L-2$ as one matrix $\\theta^{L-2}$, we can predict all activation of layer $L-1$ as:  \n",
    "\n",
    "$$a^{L-1} = f(\\theta^{L-2} a^{L-2})$$  \n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl22.png\" width=\"50%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation (3)\n",
    "- Then the gradient of a connection $\\theta_{ij}^{L-2}$ with respect to the loss function will be:  \n",
    "\n",
    "$$\\frac{dl}{d\\theta_{ij}^{L-2}} = \\frac{dz_i^{L-1}}{d\\theta_{ij}{L-2}}\\frac{da_i^{L-1}}{dz_i^{L-1}} \\sum{\\frac{dz^L}{da_i^{L-1}} \\frac{da^L}{dz^L} \\frac{dl}{da^L}}$$  \n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl22.png\" width=\"50%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation (4)\n",
    "- Then the gradient of a connection $\\theta_{jk}^{L-3}$ with respect to the loss function will be:  \n",
    "\n",
    "$$\\frac{dl}{d\\theta_{jk}^{L-3}} = \\frac{dz_j^{L-2}}{d\\theta_{jk}^{L-3}}\\frac{da_j^{L-2}}{dz_j^{L-2}} \\sum{\\frac{dz_i^{L-1}}{da_j^{L-2}} \\frac{da_i^{L-1}}{dz_i^{L-1}}} \\sum{\\frac{dz^L}{da_i^{L-1}} \\frac{da^L}{dz^L} \\frac{dl}{da^L}} $$  \n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl22.png\" width=\"50%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation (5)\n",
    "- The same structure gets repeated during the chain rule:\n",
    "\n",
    "$$\\frac{dl}{d\\theta_{ij}^{L-2}} = \\frac{dz_i^{L-1}}{d\\theta_{ij}{L-2}}\\frac{da_i^{L-1}}{dz_i^{L-1}} \\sum{\\frac{dz^L}{da_i^{L-1}} \\frac{da^L}{dz^L} \\frac{dl}{da^L}}$$  \n",
    "\n",
    "$$\\frac{dl}{d\\theta_{jk}^{L-3}} = \\frac{dz_j^{L-2}}{d\\theta_{jk}^{L-3}}\\frac{da_j^{L-2}}{dz_j^{L-2}} \\sum{\\frac{dz_i^{L-1}}{da_j^{L-2}} \\frac{da_i^{L-1}}{dz_i^{L-1}}} \\sum{\\frac{dz^L}{da_i^{L-1}} \\frac{da^L}{dz^L} \\frac{dl}{da^L}}$$\n",
    "\n",
    "- Therefore, we can *backpropagate* the gradient of the loss function.  \n",
    "- Notice also, that we reuse $a$ and $z$ multiple times, therefore we could precompute them.  \n",
    "- Consequently, we could forward propagate $a$ and $z$ and *backpropagate* the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation algorithm\n",
    "\n",
    "Forward propagation\n",
    "1. From layer $1$ thought $L$  \n",
    "  1.1 Compute $a$ and $z$\n",
    "\n",
    "Backpropagation\n",
    "1. Define $\\delta_i^L = a^L-y$ (gradient of loss function)\n",
    "2. From layer $L–1$ to $1$  \n",
    "  2.1 Define $\\delta_j^{L-1} = a_j^{L-1} (1 - a_j^{L-1}) \\sum{\\theta_{ij}^{L-1} \\delta_i^L}$\n",
    "\n",
    "The gradients will be computed as follows:  \n",
    "$$\\frac{dl}{d\\theta_{ij}^k} = a_j^k a_i^{k+1} (1 - a_i^{k+1}) \\sum{a_i^{k+1} \\delta_i^{k+1}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problems with classic methods\n",
    "- The more layers, the more complex representations can be learned.  \n",
    "\n",
    "- However, more layers also implies longer chains.  \n",
    "\n",
    "- This produces numerical errors and small changes in learning.  \n",
    "\n",
    "- Groundbreaking paper in 2006 proposes to train deep architectures in a novel way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep learning\n",
    "- Also, new developments in:\n",
    "  - Training techniques (2006)\n",
    "  - GPU computing (2008)\n",
    "  - Big data.\n",
    "  - New types of architectures (new neurons and layers.)\n",
    "  \n",
    "- This opened the door to train increasingly more complex models.  \n",
    "\n",
    "- Next class we will take a look at these advances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other architectures\n",
    "- Multi-layer perceptron looses spatial location (specially in images.)  \n",
    "\n",
    "- Some features are independent of location.\n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl23.png\" width=\"80%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional neural networks\n",
    "- Create translational-invariant spatial filters (share weights.)\n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl24_3.png\" width=\"90%\" align=\"center\"></center>\n",
    "<br>\n",
    "<center><sup>http://cs231n.github.io/convolutional-networks/</sup></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional neural networks (2)\n",
    "- It can learn filters similar to what is observed in nature!\n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl25.png\" width=\"90%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional neural networks (3)\n",
    "- Digits classification: classic MNIST problem.\n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl26.png\" width=\"50%\" align=\"center\"></center>\n",
    "<br>\n",
    "<center><sup>http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html</sup></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dealing with temporal data\n",
    "- Sometimes we want to capture temporal-invariance:\n",
    "  - E.g., in chess, the state of the next move only depends on the current move.\n",
    "  - Makes learning more efficient.\n",
    "  - Allows to interpret results.\n",
    "  \n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl27.png\" width=\"55%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent neural networks\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl28.png\" width=\"75%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent neural networks (2)\n",
    "- Naïve recurrent neural network training leads to numerical problems:\n",
    "$$y = h(A(A(A(\\ldots A(y_{t-T}))$$  \n",
    "\n",
    "- Why? How would the chain rule apply here?  \n",
    "\n",
    "- Other more advanced neural network allows to learn long-term dependencies easier.  \n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl29.png\" width=\"70%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recurrent neural networks (3)\n",
    "- Handwriting generation:\n",
    "  http://www.cs.toronto.edu/~graves/handwriting.html  \n",
    "  \n",
    "  \n",
    "- Generating Wikipedia articles:  \n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl30.png\" width=\"100%\" align=\"center\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More complex temporal problems\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl31.png\" width=\"100%\" align=\"center\"></center>  \n",
    "<br>\n",
    "<center>Can you think of examples for each of this cases?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More complex temporal problems (2)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl32.png\" width=\"100%\" align=\"center\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More complex temporal problems (3)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl33.png\" width=\"100%\" align=\"center\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More complex temporal problems (4)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl34.png\" width=\"100%\" align=\"center\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reinforcement learning\n",
    "- Given semi-supervised feedback, learn how to perform actions so as to maximize total reward.  \n",
    "\n",
    "- Classical framework to study behavior in humans and animals.  \n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl35.png\" width=\"50%\" align=\"center\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reinforcement learning (2)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl36.png\" width=\"100%\" align=\"center\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reinforcement learning (3)\n",
    "<br>\n",
    "<center>http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html</center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inferring intentions\n",
    "![](./images/dota.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WaveNet\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl38.png\" width=\"60%\" align=\"center\"></center>  \n",
    "<br>\n",
    "<center><sup>https://deepmind.com/blog/wavenet-generative-model-raw-audio/</sup></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WaveNet\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl38_4.png\" width=\"60%\" align=\"center\"></center>  \n",
    "<br>\n",
    "<center><sup>https://deepmind.com/blog/wavenet-generative-model-raw-audio/</sup></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WaveNet\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl38_5.png\" width=\"90%\" align=\"center\"></center>  \n",
    "<br>\n",
    "<center><sup>https://deepmind.com/blog/wavenet-generative-model-raw-audio/</sup></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adversarial Neural Networks\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl39.png\" width=\"90%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adversarial Neural Networks (2)\n",
    "https://thispersondoesnotexist.com/\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl40.png\" width=\"90%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adversarial Neural Networks (3)\n",
    "<br>\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl41.png\" width=\"90%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adversarial Neural Networks (4)\n",
    "<center><img src=\"./images/unit-10/unit-10-0_csordl42.png\" width=\"55%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/unit-10/unit-10-0_csordl43.png\" width=\"100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Take home messages\n",
    "- Neural networks try to mimic how the brain works: hierarchical layers of non-linear functions.  \n",
    "\n",
    "- Neural networks take time to train and overfit badly.  \n",
    "\n",
    "- Neural networks need big data.  \n",
    "\n",
    "- Neural networks are hard or impossible to interpret.  \n",
    "\n",
    "- Backpropagation allows efficient computation of gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activity\n",
    "\n",
    "1. Non-linearity\n",
    "    1. Go to https://playground.tensorflow.org/\n",
    "    1. Choose the top right dataset (\"XOR\" problem)\n",
    "    1. Choose 1 hidden layer\n",
    "    1. Click play. What happens?\n",
    "1. Feature enginering\n",
    "    1. Follow all steps above but additionally select $X_1 X_2$ feature\n",
    "    1. Click play. What happens?\n",
    "1. No feature engineering\n",
    "    1. De-select the $X_1 X_2$ feature\n",
    "    1. Create 3 hidden layers\n",
    "    1. Click play. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Activity (answers)\n",
    "\n",
    "1. Non-linearity\n",
    "   1. It will be impossible for a linear function to work\n",
    "1. Feature engineering\n",
    "   1. The feature we added makes the space linearly separable and therefore 1 neuron works. The key is that we need to be clever about the features\n",
    "1. No feature engineering\n",
    "   1. The neural network created the features for us and is able to separate the classes."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "rise": {
   "chalkboard": {
    "color": [
     "rgb(250, 250, 250)",
     "rgb(250, 250, 250)"
    ]
   },
   "enable_chalkboard": true,
   "footer": "<h3><span style='color: orange'>Science of Science Summer School 2022</span></h3>",
   "header": "<h3>Day 3 - Deep Learning</h3>",
   "show_buttons_on_startup": false,
   "slideNumber": true,
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
